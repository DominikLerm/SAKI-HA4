{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAKI HA 4 WAREHOUSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdptoolbox, mdptoolbox.example\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w', 'b', 'r']\n",
      "['e', 'w', 'b', 'r']\n",
      "['in', 'out']\n",
      "[('in', 'w'), ('in', 'b'), ('in', 'r'), ('out', 'w'), ('out', 'b'), ('out', 'r')]\n"
     ]
    }
   ],
   "source": [
    "items = [\"w\", \"b\", \"r\"]\n",
    "container_state = [\"e\", \"w\", \"b\", \"r\"]\n",
    "operations = [\"in\", \"out\"]\n",
    "actions = []\n",
    "for operation in operations:\n",
    "    for item in items:\n",
    "        actions.append((operation, item))\n",
    "\n",
    "print(items)\n",
    "print(container_state)\n",
    "print(operations)\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_warehouse(x, y):\n",
    "    warehouse = []    \n",
    "    for i in range(0, x):\n",
    "        for j in range(0, y):\n",
    "            warehouse.append((i,j))\n",
    "            \n",
    "    return warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (0, 1), (1, 0), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "warehouse = create_warehouse(2, 2)\n",
    "print(warehouse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the total number of states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getnrstates(warehouse, actions, container_state):\n",
    "    nrstates = (len(container_state) ** len(warehouse)) * len(actions)\n",
    "    return nrstates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "print(getnrstates(warehouse, actions, container_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of the warehousestates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfieldstates(warehouse, container_state):  \n",
    "    return list(itertools.product(container_state, repeat=len(warehouse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first state:('e', 'e', 'e', 'e')\n",
      "last state: ('r', 'r', 'r', 'r')\n",
      "total number of fieldstates: 256\n"
     ]
    }
   ],
   "source": [
    "fieldstates = getfieldstates(warehouse, container_state)\n",
    "print(\"first state:\" + str(fieldstates[0]))\n",
    "print(\"last state: \" + str(fieldstates[-1]))\n",
    "print(\"total number of fieldstates: \" + str(len(fieldstates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Generate matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create reward matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward_distance(warehouse):\n",
    "    rewardvec = [1/(2*(container[0]+container[1] + 1)) for container in warehouse]\n",
    "    return rewardvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.25, 0.25, 0.16666666666666666]\n"
     ]
    }
   ],
   "source": [
    "rewardvec = get_reward_distance(warehouse)\n",
    "print(rewardvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start with empty matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:(6, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "transition = np.zeros((len(actions), len(fieldstates), len(fieldstates)))\n",
    "reward = np.zeros((len(actions), len(fieldstates), len(fieldstates)))\n",
    "print(\"shape:\" + str(np.shape(transition)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helperfunction, which checks if an action is possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def checkaction(action, fieldstate):\n",
    "    if action[0] == \"in\":\n",
    "        if \"e\" in fieldstate:\n",
    "            return True\n",
    "    elif action[0] == \"out\":\n",
    "        if action[1] == \"w\":\n",
    "            if \"w\" in fieldstate:\n",
    "                return True\n",
    "        if action[1] == \"b\":\n",
    "            if \"b\" in fieldstate:\n",
    "                return True\n",
    "        if action[1] == \"r\":\n",
    "            if \"r\" in fieldstate:\n",
    "                return True\n",
    "    return False\n",
    "action1 = checkaction((\"in\",\"r\"),(\"r\",\"e\",\"w\",\"e\"))\n",
    "action2 = checkaction((\"out\",\"r\"),(\"b\",\"w\",\"e\",\"e\"))\n",
    "print(action1)\n",
    "print(action2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helperfunction, which search given state in a fieldstate and returns the indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "def findvalueinlist(value, mylist):\n",
    "    indices = [i for i, x in enumerate(mylist) if x == value]\n",
    "    return indices\n",
    "print(findvalueinlist(\"e\", (\"e\", \"b\", \"w\", \"e\", \"e\", \"r\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate how often the unique colors appear in the trainingdata, for the final reward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w, b, r\n",
      "[0.2556987115956392, 0.25057813016187647, 0.4937231582424843]\n"
     ]
    }
   ],
   "source": [
    "def calc_appearancevec():\n",
    "    txt = open('warehousetraining.txt')\n",
    "    appearancecount = [0,0,0]\n",
    "    itemscount = 0\n",
    "    for line in txt:\n",
    "        linelist = line.split('\\t')\n",
    "        color = linelist[1].strip('\\n')\n",
    "        if color == 'white':\n",
    "            appearancecount[0] += 1 \n",
    "        elif color == 'blue':\n",
    "            appearancecount[1] += 1 \n",
    "        elif color == 'red':\n",
    "            appearancecount[2] += 1 \n",
    "        itemscount += 1\n",
    "    appearancevec = [appearance / itemscount for appearance in appearancecount]\n",
    "    return(appearancevec)\n",
    "appearancevec = calc_appearancevec()\n",
    "print(\"w, b, r\")\n",
    "print(appearancevec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_matrices(fieldstates, actions):\n",
    "    transition = np.zeros((len(actions), len(fieldstates), len(fieldstates)))\n",
    "    reward = np.zeros((len(actions), len(fieldstates), len(fieldstates)))\n",
    "    for i, action in enumerate(actions):\n",
    "        for j, state in enumerate(fieldstates):\n",
    "            if checkaction(action, state) == False:\n",
    "                transition[i, j, j] = 1\n",
    "            else:\n",
    "                if action[0] == \"in\":\n",
    "                    indices = findvalueinlist( \"e\",state)\n",
    "                    prob = 1/len(indices)\n",
    "                    for index in indices:\n",
    "                        newfieldstate = list(state)\n",
    "                        newfieldstate[index] = action[1]\n",
    "                        newfieldstateindex = fieldstates.index(tuple(newfieldstate))\n",
    "                        transition[i, j , newfieldstateindex] = prob\n",
    "                        reward[i, j, newfieldstateindex] = rewardvec[index] * appearancevec[items.index(action[1])]\n",
    "                elif action[0] == \"out\":\n",
    "                    indices = findvalueinlist(action[1], state)\n",
    "                    \n",
    "                    prob = 1/len(indices)\n",
    "                    for index in indices:\n",
    "                        newfieldstate = list(state)\n",
    "                        newfieldstate[index] = \"e\"\n",
    "                        newfieldstateindex = fieldstates.index(tuple(newfieldstate))\n",
    "                        transition[i, j , newfieldstateindex] = prob\n",
    "                        reward[i, j, newfieldstateindex] = rewardvec[index] * appearancevec[items.index(action[1])]\n",
    "    \n",
    "    return transition, reward\n",
    "transition_matrix, reward_matrix = calc_matrices(fieldstates, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the transition and reward matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('e', 'e', 'e', 'e') + ('in', 'w') ->\n",
      "\n",
      "Transition matrix\n",
      "[0.   0.25 0.   0.   0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.25 0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.  ]\n",
      "Reward matrix\n",
      "[0.         0.04261645 0.         0.         0.06392468 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.06392468 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.12784936 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "\n",
      "Indicies of all state transitions: [1, 4, 16, 64]\n",
      "Resulting next states:\n",
      "('e', 'e', 'e', 'w')\n",
      "('e', 'e', 'w', 'e')\n",
      "('e', 'w', 'e', 'e')\n",
      "('w', 'e', 'e', 'e')\n"
     ]
    }
   ],
   "source": [
    "stateid = 0\n",
    "actionid = 0\n",
    "print(str(fieldstates[stateid]) + \" + \" + str(actions[actionid]) + \" ->\\n\")\n",
    "print(\"Transition matrix\")\n",
    "print(transition_matrix[actionid, stateid])\n",
    "print(\"Reward matrix\")\n",
    "print(reward_matrix[actionid, stateid])\n",
    "white_index = findvalueinlist(max(transition_matrix[actionid, stateid]) ,transition_matrix[actionid, stateid])\n",
    "print(\"\\nIndicies of all state transitions: \" + str(white_index))\n",
    "print(\"Resulting next states:\")\n",
    "for wi in white_index:\n",
    "    print(fieldstates[wi])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished calculation\n"
     ]
    }
   ],
   "source": [
    "policyIt = mdptoolbox.mdp.PolicyIteration(transition_matrix, reward_matrix, 0.9)\n",
    "policyIt.run()\n",
    "\n",
    "qlearning = mdptoolbox.mdp.QLearning(transition_matrix, reward_matrix, 0.9)\n",
    "qlearning.run()\n",
    "\n",
    "valIt = mdptoolbox.mdp.ValueIteration(transition_matrix, reward_matrix, 0.9)\n",
    "valIt.run()\n",
    "print(\"finished calculation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For a comparision we create a simple greedy model, which always picks the action with the highest reward. We use the two files of generated action, a short and a long actionlist, to calculate the sum of the rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_model(testactions):\n",
    "    current_state = 0\n",
    "    rewardsum = 0\n",
    "\n",
    "    for action in testactions:\n",
    "        indices = findvalueinlist(max(transition_matrix[actions.index(action), current_state]) ,transition_matrix[actions.index(action), current_state])  \n",
    "        indices_reward = [reward_matrix[actions.index(action), current_state, index] for index in indices]\n",
    "        next_state = indices[indices_reward.index(max(indices_reward))]\n",
    "        #print(str(fieldstates[current_state]) + \"+\" + str(action) + \"->\" + str(fieldstates[next_state]) + \"reward: \" + str(reward_matrix[actions.index(action), current_state, next_state]))\n",
    "        rewardsum += reward_matrix[actions.index(action), current_state, next_state]\n",
    "        current_state = next_state\n",
    "        \n",
    "    #rint(\"Total Reward: \" + str(rewardsum))\n",
    "    return rewardsum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_testorder(testfilepath):\n",
    "    testactions = []\n",
    "    file = open(testfilepath)\n",
    "    for line in file:\n",
    "        linelist = line.split('\\t')\n",
    "        if linelist[0] == \"store\":\n",
    "            variant = \"in\"\n",
    "        elif linelist[0] == \"restore\":\n",
    "            variant = \"out\"\n",
    "        if linelist[1].strip('\\n') == \"white\":\n",
    "            color = \"w\"\n",
    "        elif linelist[1].strip('\\n') == \"blue\":\n",
    "            color = \"b\"\n",
    "        elif linelist[1].strip('\\n') == \"red\":\n",
    "            color = \"r\"\n",
    "            \n",
    "        testactions.append((variant, color))\n",
    "    return(testactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "12108\n"
     ]
    }
   ],
   "source": [
    "testactions_short = create_testorder(\"warehouseorder.txt\")\n",
    "testactions_long = create_testorder(\"warehousetraining.txt\")\n",
    "print(len(testactions_short))\n",
    "print(len(testactions_long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the 3 models with the short actionlist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(testactions, model):\n",
    "    current_state = 0\n",
    "    rewardsum = 0\n",
    "\n",
    "    for action in testactions:\n",
    "        indices = findvalueinlist(max(transition_matrix[actions.index(action), current_state]) ,transition_matrix[actions.index(action), current_state])  \n",
    "        values = [model.V[index] for index in indices]\n",
    "        next_state = indices[values.index(max(values))]\n",
    "        #print(fieldstates[next_state])\n",
    "        rewardsum += reward_matrix[actions.index(action), current_state, next_state]\n",
    "        current_state = next_state    \n",
    "    print(\"Total Reward: \" + str(rewardsum))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short actionlist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHORT_LIST\n",
      "-------greedyModel-------\n",
      "Total Reward: 5.937782182579012\n",
      "--------policyIt---------\n",
      "Total Reward: 5.393926880299527\n",
      "--------qlearning--------\n",
      "Total Reward: 4.757873582204604\n",
      "---------valIt-----------\n",
      "Total Reward: 5.393926880299527\n"
     ]
    }
   ],
   "source": [
    "print(\"SHORT_LIST\")\n",
    "print(\"-------greedyModel-------\")\n",
    "print(\"Total Reward: \" + str(greedy_model(testactions_short)))\n",
    "print(\"--------policyIt---------\")\n",
    "test_model(testactions_short, policyIt)\n",
    "print(\"--------qlearning--------\")\n",
    "test_model(testactions_short, qlearning)\n",
    "print(\"---------valIt-----------\")\n",
    "test_model(testactions_short, valIt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long actionlist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LONG_LIST\n",
      "-------greedyModel-------\n",
      "Total Reward: 1181.0238685167508\n",
      "--------policyIt---------\n",
      "Total Reward: 1193.400561612256\n",
      "--------qlearning--------\n",
      "Total Reward: 1043.510654113055\n",
      "---------valIt-----------\n",
      "Total Reward: 1193.400561612256\n"
     ]
    }
   ],
   "source": [
    "print(\"LONG_LIST\")\n",
    "print(\"-------greedyModel-------\")\n",
    "print(\"Total Reward: \" + str(greedy_model(testactions_long)))\n",
    "print(\"--------policyIt---------\")\n",
    "test_model(testactions_long, policyIt)\n",
    "print(\"--------qlearning--------\")\n",
    "test_model(testactions_long, qlearning)\n",
    "print(\"---------valIt-----------\")\n",
    "test_model(testactions_long, valIt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
